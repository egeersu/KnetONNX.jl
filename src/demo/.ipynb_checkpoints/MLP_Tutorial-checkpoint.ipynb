{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Package\n",
    "* this makes sure we can find KnetONNX.jl which is the main file of the package\n",
    "* to get rid of the messages, run the cell a second time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "push!(LOAD_PATH, \".\")\n",
    "\n",
    "# go to the module: KnetONNX.jl to see which functions are exported. \n",
    "using Knet\n",
    "using KnetONNX;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/egeersu/Desktop/KnetONNX/@test_onnx_files/mlp.onnx\""
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the path to mlp.onnx which is in folder: @test_onnx_files\n",
    "# it is a simple multi-layer-perceptron exported from PyTorch\n",
    "file_path = \"/Users/egeersu/Desktop/KnetONNX/@test_onnx_files/mlp.onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnetONNX.Types.Graph(Any[KnetONNX.Types.Node(AbstractString[\"input.1\", \"linear1.weight\", \"linear1.bias\"], AbstractString[\"5\"], \"\", \"Gemm\", \"\", Dict{Any,Any}(:alpha => 1.0f0,:beta => 1.0f0,:transB => 1), \"\"), KnetONNX.Types.Node(AbstractString[\"5\", \"linear2.weight\", \"linear2.bias\"], AbstractString[\"6\"], \"\", \"Gemm\", \"\", Dict{Any,Any}(:alpha => 1.0f0,:beta => 1.0f0,:transB => 1), \"\"), KnetONNX.Types.Node(AbstractString[\"6\"], AbstractString[\"7\"], \"\", \"Relu\", \"\", Dict{Any,Any}(), \"\"), KnetONNX.Types.Node(AbstractString[\"7\"], AbstractString[\"8\"], \"\", \"LeakyRelu\", \"\", Dict{Any,Any}(:alpha => 0.5f0), \"\")], \"torch-jit-export\", Dict{Any,Any}(\"linear1.bias\" => Float32[-0.06265882, 0.07226259, -0.08190198, 0.008811131, -0.076628305, 0.0030988008, 0.015958883, 0.0028882474, 0.05794201, -0.022151016, 0.07181152, -0.018054068, 0.033906244, -0.017747007, 0.08845409, -0.014154993, -0.07355064, 0.061681457, 0.03672152, -0.044710457],\"linear2.weight\" => Float32[-0.14748284 -0.18082848; -0.21550609 -0.11113948; … ; -0.072905004 0.026493043; -0.014616266 0.024197787],\"linear2.bias\" => Float32[-0.048644066, 0.14315096],\"linear1.weight\" => Float32[0.0023994297 -0.029352963 … 8.748472e-5 0.09451694; 0.08585521 0.029646344 … -0.059136786 0.09001721; … ; 0.062942185 0.032472588 … 0.05123458 -0.06568958; 0.008416399 0.022889376 … -0.09236989 0.05262976]), \"\", KnetONNX.Types.ValueInfo[KnetONNX.Types.ValueInfo(\"input.1\", \"\")], KnetONNX.Types.ValueInfo[KnetONNX.Types.ValueInfo(\"8\", \"\")], KnetONNX.Types.ValueInfo[])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's turn it into a graph (KnetONNX.graph)\n",
    "# ugly right?\n",
    "graph1 = ONNXtoGraph(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model inputs: [\"input.1\"]\n",
      "model outputs: [\"8\"]\n",
      "(op1) Gemm\n",
      "\tinput1: input.1\n",
      "\tinput2: linear1.weight\n",
      "\tinput3: linear1.bias\n",
      "\toutput1: 5\n",
      "(op2) Gemm\n",
      "\tinput1: 5\n",
      "\tinput2: linear2.weight\n",
      "\tinput3: linear2.bias\n",
      "\toutput1: 6\n",
      "(op3) Relu\n",
      "\tinput1: 6\n",
      "\toutput1: 7\n",
      "(op4) LeakyRelu\n",
      "\tinput1: 7\n",
      "\toutput1: 8\n"
     ]
    }
   ],
   "source": [
    "# here is a prettier print function\n",
    "PrintGraph(graph1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KnetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnetModel(Dict{Any,Any}(\"5\" => Nothing,\"input.1\" => Nothing,\"6\" => Nothing,\"7\" => Nothing,\"8\" => Nothing), Any[ModelLayer([\"input.1\"], KnetONNX.KnetLayers.Linear(KnetONNX.KnetLayers.Multiply(Float32[0.0023994297 0.08585521 … 0.062942185 0.008416399; -0.029352963 0.029646344 … 0.032472588 0.022889376; … ; 8.748472e-5 -0.059136786 … 0.05123458 -0.09236989; 0.09451694 0.09001721 … -0.06568958 0.05262976]), Float32[-0.06265882, 0.07226259, -0.08190198, 0.008811131, -0.076628305, 0.0030988008, 0.015958883, 0.0028882474, 0.05794201, -0.022151016, 0.07181152, -0.018054068, 0.033906244, -0.017747007, 0.08845409, -0.014154993, -0.07355064, 0.061681457, 0.03672152, -0.044710457]), AbstractString[\"5\"]), ModelLayer([\"5\"], KnetONNX.KnetLayers.Linear(KnetONNX.KnetLayers.Multiply(Float32[-0.14748284 -0.21550609 … -0.072905004 -0.014616266; -0.18082848 -0.11113948 … 0.026493043 0.024197787]), Float32[-0.048644066, 0.14315096]), AbstractString[\"6\"]), ModelLayer(AbstractString[\"6\"], KnetONNX.KnetLayers.ReLU(), AbstractString[\"7\"]), ModelLayer(AbstractString[\"7\"], KnetONNX.KnetLayers.LeakyReLU(0.5f0), AbstractString[\"8\"])], [\"input.1\"], [\"8\"])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call the KnetModel constructor with the graph we just created\n",
    "# it creates a the corresponding KnetModel\n",
    "model = KnetModel(graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "KnetModel\n",
       "\n",
       "* tensors: A dictionary. Given the tensor name as a string, returns the actual tensor.\n",
       "\n",
       "* model_layers: returns the list of layers (the actual layers themselves)\n",
       "\n",
       "* model_inputs: returns the list of inputs (the names of the tensors)\n",
       "\n",
       "* model_outputs: returns the list of outputs (the names of the outputs)\n",
       "\\end{verbatim}\n",
       "Given a Graph, construct the corresponding KnetModel\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "KnetModel\n",
       "\n",
       "* tensors: A dictionary. Given the tensor name as a string, returns the actual tensor.\n",
       "\n",
       "* model_layers: returns the list of layers (the actual layers themselves)\n",
       "\n",
       "* model_inputs: returns the list of inputs (the names of the tensors)\n",
       "\n",
       "* model_outputs: returns the list of outputs (the names of the outputs)\n",
       "```\n",
       "\n",
       "Given a Graph, construct the corresponding KnetModel\n"
      ],
      "text/plain": [
       "\u001b[36m  KnetModel\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  * tensors: A dictionary. Given the tensor name as a string, returns the actual tensor.\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  * model_layers: returns the list of layers (the actual layers themselves)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  * model_inputs: returns the list of inputs (the names of the tensors)\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  * model_outputs: returns the list of outputs (the names of the outputs)\u001b[39m\n",
       "\n",
       "  Given a Graph, construct the corresponding KnetModel"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what this KnetModel is!\n",
    "# You can read the documentation with:\n",
    "@doc KnetModel\n",
    "\n",
    "# it has 4 fields:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.inputs & model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.model_inputs = [\"input.1\"]\n",
      "model.model_outputs = [\"8\"]\n"
     ]
    }
   ],
   "source": [
    "# realize that model_inputs and model_outputs are the same as the graph we just printed.\n",
    "@show model.model_inputs\n",
    "@show model.model_outputs;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.model_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Any,1}:\n",
       " ModelLayer([\"input.1\"], KnetONNX.KnetLayers.Linear(KnetONNX.KnetLayers.Multiply(Float32[0.0023994297 0.08585521 … 0.062942185 0.008416399; -0.029352963 0.029646344 … 0.032472588 0.022889376; … ; 8.748472e-5 -0.059136786 … 0.05123458 -0.09236989; 0.09451694 0.09001721 … -0.06568958 0.05262976]), Float32[-0.06265882, 0.07226259, -0.08190198, 0.008811131, -0.076628305, 0.0030988008, 0.015958883, 0.0028882474, 0.05794201, -0.022151016, 0.07181152, -0.018054068, 0.033906244, -0.017747007, 0.08845409, -0.014154993, -0.07355064, 0.061681457, 0.03672152, -0.044710457]), AbstractString[\"5\"])\n",
       " ModelLayer([\"5\"], KnetONNX.KnetLayers.Linear(KnetONNX.KnetLayers.Multiply(Float32[-0.14748284 -0.21550609 … -0.072905004 -0.014616266; -0.18082848 -0.11113948 … 0.026493043 0.024197787]), Float32[-0.048644066, 0.14315096]), AbstractString[\"6\"])                                                                                                                                                                                                                                                                                                                                                         \n",
       " ModelLayer(AbstractString[\"6\"], KnetONNX.KnetLayers.ReLU(), AbstractString[\"7\"])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       " ModelLayer(AbstractString[\"7\"], KnetONNX.KnetLayers.LeakyReLU(0.5f0), AbstractString[\"8\"])                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   "
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.layers is a list of all the layers in our model. The order does not matter.\n",
    "model.model_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length(model.model_layers) = 4\n"
     ]
    }
   ],
   "source": [
    "# When you print it things get ugly so let us just check the length of it.\n",
    "# It should be 4, since we have 4 operations in our graph\n",
    "@show length(model.model_layers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelLayer([\"input.1\"], KnetONNX.KnetLayers.Linear(KnetONNX.KnetLayers.Multiply(Float32[0.0023994297 0.08585521 … 0.062942185 0.008416399; -0.029352963 0.029646344 … 0.032472588 0.022889376; … ; 8.748472e-5 -0.059136786 … 0.05123458 -0.09236989; 0.09451694 0.09001721 … -0.06568958 0.05262976]), Float32[-0.06265882, 0.07226259, -0.08190198, 0.008811131, -0.076628305, 0.0030988008, 0.015958883, 0.0028882474, 0.05794201, -0.022151016, 0.07181152, -0.018054068, 0.033906244, -0.017747007, 0.08845409, -0.014154993, -0.07355064, 0.061681457, 0.03672152, -0.044710457]), AbstractString[\"5\"])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's check out what these layers really are by looking at the first layer.\n",
    "layer1 = model.model_layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typeof(layer1) = ModelLayer\n"
     ]
    }
   ],
   "source": [
    "@show typeof(layer1);\n",
    "# turns out it's of type: ModelLayer\n",
    "# I will explain it later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.tensors\n",
    "* The 4th and the last field is tensors.\n",
    "* It's simply a dictionary: the tensor's name => the tensor itself\n",
    "* It includes the input tensors, output tensors, and all other intermediate tensors.\n",
    "* Whenever we do a calculation we go to model.tensors and update the corresponding tensors.\n",
    "* For our MLP model, we expect model.tensors[\"8\"] to hold the output to our model in the en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 5 entries:\n",
       "  \"5\"       => Nothing\n",
       "  \"input.1\" => Nothing\n",
       "  \"6\"       => Nothing\n",
       "  \"7\"       => Nothing\n",
       "  \"8\"       => Nothing"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns out they are all nothing. That makes sense since we did not calculate anything yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So how does the model know which way to forward our inputs? \n",
    "# model.model_layers is simply an unordered list of ModelLayers\n",
    "# the information is stored WITHIN those things of type: ModelLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "ModelLayer\n",
       "    * inputs: a list of tensor names.\n",
       "      These tensors will be used for forward calculation of the layer.\n",
       "    * outputs: a list of tensor names.\n",
       "      The outputs of the forward calculation will be saved to Model.tensors under these keys.\n",
       "    * layer: a Knet Layer.\n",
       "      If you are constructing your own ModelLayer make sure the number of inputs and outputs matches the functionality of the KnetLayer you are using.\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "ModelLayer\n",
       "    * inputs: a list of tensor names.\n",
       "      These tensors will be used for forward calculation of the layer.\n",
       "    * outputs: a list of tensor names.\n",
       "      The outputs of the forward calculation will be saved to Model.tensors under these keys.\n",
       "    * layer: a Knet Layer.\n",
       "      If you are constructing your own ModelLayer make sure the number of inputs and outputs matches the functionality of the KnetLayer you are using.\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  ModelLayer\u001b[39m\n",
       "\u001b[36m      * inputs: a list of tensor names.\u001b[39m\n",
       "\u001b[36m        These tensors will be used for forward calculation of the layer.\u001b[39m\n",
       "\u001b[36m      * outputs: a list of tensor names.\u001b[39m\n",
       "\u001b[36m        The outputs of the forward calculation will be saved to Model.tensors under these keys.\u001b[39m\n",
       "\u001b[36m      * layer: a Knet Layer.\u001b[39m\n",
       "\u001b[36m        If you are constructing your own ModelLayer make sure the number of inputs and outputs matches the functionality of the KnetLayer you are using.\u001b[39m"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc ModelLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us grab a ModelLayer to see what it is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelLayer([\"input.1\"], KnetONNX.KnetLayers.Linear(KnetONNX.KnetLayers.Multiply(Float32[0.0023994297 0.08585521 … 0.062942185 0.008416399; -0.029352963 0.029646344 … 0.032472588 0.022889376; … ; 8.748472e-5 -0.059136786 … 0.05123458 -0.09236989; 0.09451694 0.09001721 … -0.06568958 0.05262976]), Float32[-0.06265882, 0.07226259, -0.08190198, 0.008811131, -0.076628305, 0.0030988008, 0.015958883, 0.0028882474, 0.05794201, -0.022151016, 0.07181152, -0.018054068, 0.033906244, -0.017747007, 0.08845409, -0.014154993, -0.07355064, 0.061681457, 0.03672152, -0.044710457]), AbstractString[\"5\"])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_layer1 = model.model_layers[1]\n",
    "# eww, ugly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{String,1}:\n",
       " \"input.1\""
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but it simply has 3 fields\n",
    "\n",
    "# FIELD 1: inputs\n",
    "# a list of the NAMES of tensors that will be used as input in this calculation\n",
    "model_layer1.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nothing"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# realize that they will be keys in model.tensors. So we will be grabbing the tensors from there.\n",
    "model.tensors[model_layer1.inputs[1]]\n",
    "# of course it is Nothing right now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{AbstractString,1}:\n",
       " \"5\""
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIELD2: outputs\n",
    "# a list of the NAMES of tensors that will be the outputs of this calculation\n",
    "# realize that they are also in model.tensors.\n",
    "model_layer1.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnetONNX.KnetLayers.Linear(KnetONNX.KnetLayers.Multiply(Float32[0.0023994297 0.08585521 … 0.062942185 0.008416399; -0.029352963 0.029646344 … 0.032472588 0.022889376; … ; 8.748472e-5 -0.059136786 … 0.05123458 -0.09236989; 0.09451694 0.09001721 … -0.06568958 0.05262976]), Float32[-0.06265882, 0.07226259, -0.08190198, 0.008811131, -0.076628305, 0.0030988008, 0.015958883, 0.0028882474, 0.05794201, -0.022151016, 0.07181152, -0.018054068, 0.033906244, -0.017747007, 0.08845409, -0.014154993, -0.07355064, 0.061681457, 0.03672152, -0.044710457])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FIELD3: KnetLayer\n",
    "# a KnetLayer is THE layer. All the ugly matrix multiplication math is in these layers.\n",
    "# this guy takes an input and spits the output.\n",
    "model_layer1.layer\n",
    "# this one is a Linear Layer (you can check KnetLayers folder for detail or call @doc KnetONNX.KnetLayers.Linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Pass\n",
    "\n",
    "* We now know the components of the model!\n",
    "* Let us do a simple forward pass with a dummy input: x1\n",
    "* What should the input size be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnetONNX.KnetLayers.Linear(KnetONNX.KnetLayers.Multiply(Float32[0.0023994297 0.08585521 … 0.062942185 0.008416399; -0.029352963 0.029646344 … 0.032472588 0.022889376; … ; 8.748472e-5 -0.059136786 … 0.05123458 -0.09236989; 0.09451694 0.09001721 … -0.06568958 0.05262976]), Float32[-0.06265882, 0.07226259, -0.08190198, 0.008811131, -0.076628305, 0.0030988008, 0.015958883, 0.0028882474, 0.05794201, -0.022151016, 0.07181152, -0.018054068, 0.033906244, -0.017747007, 0.08845409, -0.014154993, -0.07355064, 0.061681457, 0.03672152, -0.044710457])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#grab the first ModelLayer of our layer. This does not have to be the first layer but we know it is since this is a simple model.\n",
    "model_layer1 = model.model_layers[1]\n",
    "\n",
    "#grab its KnetLayer: it's a Linear Layer\n",
    "knet_layer1 = layer1.layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "Linear(input=inputSize, output=outputSize, winit=xavier, binit=zeros, atype=KnetLayers.arrtype)\n",
       "\\end{verbatim}\n",
       "Creates and linear layer according to given \\texttt{inputSize} and \\texttt{outputSize}.\n",
       "\n",
       "\\section{Keywords}\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{input=inputSize}   input dimension\n",
       "\n",
       "\n",
       "\\item \\texttt{output=outputSize} output dimension\n",
       "\n",
       "\n",
       "\\item \\texttt{winit=xavier}: weight initialization distribution\n",
       "\n",
       "\n",
       "\\item \\texttt{bias=zeros}: bias initialization distribution\n",
       "\n",
       "\n",
       "\\item \\texttt{atype=KnetLayers.arrtype} : array type for parameters.  Default value is KnetArray\\{Float32\\} if you have gpu device. Otherwise it is Array\\{Float32\\}\n",
       "\n",
       "\\end{itemize}\n"
      ],
      "text/markdown": [
       "```\n",
       "Linear(input=inputSize, output=outputSize, winit=xavier, binit=zeros, atype=KnetLayers.arrtype)\n",
       "```\n",
       "\n",
       "Creates and linear layer according to given `inputSize` and `outputSize`.\n",
       "\n",
       "# Keywords\n",
       "\n",
       "  * `input=inputSize`   input dimension\n",
       "  * `output=outputSize` output dimension\n",
       "  * `winit=xavier`: weight initialization distribution\n",
       "  * `bias=zeros`: bias initialization distribution\n",
       "  * `atype=KnetLayers.arrtype` : array type for parameters.  Default value is KnetArray{Float32} if you have gpu device. Otherwise it is Array{Float32}\n"
      ],
      "text/plain": [
       "\u001b[36m  Linear(input=inputSize, output=outputSize, winit=xavier, binit=zeros, atype=KnetLayers.arrtype)\u001b[39m\n",
       "\n",
       "  Creates and linear layer according to given \u001b[36minputSize\u001b[39m and \u001b[36moutputSize\u001b[39m.\n",
       "\n",
       "\u001b[1m  Keywords\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "    •    \u001b[36minput=inputSize\u001b[39m input dimension\n",
       "\n",
       "    •    \u001b[36moutput=outputSize\u001b[39m output dimension\n",
       "\n",
       "    •    \u001b[36mwinit=xavier\u001b[39m: weight initialization distribution\n",
       "\n",
       "    •    \u001b[36mbias=zeros\u001b[39m: bias initialization distribution\n",
       "\n",
       "    •    \u001b[36matype=KnetLayers.arrtype\u001b[39m : array type for parameters. Default\n",
       "        value is KnetArray{Float32} if you have gpu device. Otherwise it\n",
       "        is Array{Float32}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the documentation if you want!\n",
    "@doc KnetONNX.KnetLayers.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(knet_layer1.mult.weight) = (20, 100)\n",
      "size(knet_layer1.bias) = (20,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20,)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so let's see what this Linear Layer's weight size is:\n",
    "@show size(knet_layer1.mult.weight)\n",
    "@show size(knet_layer1.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turns out we need an input of size: (100, x) where x can be anything. Let's pick 5.\n",
    "x1 = randn(100,5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20×5 Array{Float64,2}:\n",
       "  0.480554    -0.0127278   -0.915802   -0.677104   -0.0401961\n",
       "  0.754838    -0.0363629   -0.789278    0.0144616  -0.882731 \n",
       "  0.250956    -0.483701    -0.322535   -0.121441    0.43257  \n",
       " -0.937862     0.225028     0.117094    0.61481    -0.713791 \n",
       " -0.737429     0.0161204   -0.115812    0.154845   -0.177609 \n",
       " -0.408457    -0.566552    -1.13216     0.203349    0.0713349\n",
       "  0.379293     0.462643    -0.0316664   0.267433   -0.292194 \n",
       " -0.290515     0.236075     0.550567   -0.759687    0.878719 \n",
       "  0.00744974  -0.33081      0.10554     0.0367531   1.16988  \n",
       " -0.0893771   -0.502502    -0.148824    0.104242   -1.57269  \n",
       "  0.405203     0.413644     0.307395   -0.0571488  -0.544346 \n",
       "  0.0343354    0.569743     0.38878     0.738735    0.0126414\n",
       " -0.518913    -0.366703    -0.869722   -0.209551   -0.0139192\n",
       "  0.419459     0.557384     2.00015    -0.924424    0.410382 \n",
       "  0.854258     0.00890711   1.19173     0.60773     0.1887   \n",
       " -0.360407    -0.213426    -0.70821     0.289279    0.255107 \n",
       "  0.0296418    0.497156     0.125773   -0.0836378   0.016543 \n",
       "  0.182003    -0.670861    -0.26443    -0.107263   -0.899078 \n",
       " -0.321612     0.370786     0.297403   -0.741142   -1.00306  \n",
       " -0.620467    -0.694807    -0.783769    0.118157   -0.584027 "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try it on the KnetLayer itself to see if the dimension matches up\n",
    "# We normally don't do this. We simply call: model(x1)\n",
    "knet_layer1(x1)\n",
    "\n",
    "# the output of the layer is 20 x 5 as expected.\n",
    "# Matrix sizes are inversed in knet if you are confused <3\n",
    "# (100,5) -> (20,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward begins\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×5 Array{Float64,2}:\n",
       " 0.0  0.105847   0.0       0.240075  0.375942\n",
       " 0.0  0.0276985  0.651835  0.0       0.180072"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this was just for determining the input of our model.\n",
    "# now let us call the model as it should be used.\n",
    "model(x1)\n",
    "# nice, we got the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us see what model.tensors looks like now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 5 entries:\n",
       "  \"5\"       => [0.480554 -0.0127278 … -0.677104 -0.0401961; 0.754838 -0.0363629…\n",
       "  \"input.1\" => [-0.100092 0.412201 … 0.685679 0.12627; -0.318662 1.15254 … 1.41…\n",
       "  \"6\"       => [-0.21248 0.105847 … 0.240075 0.375942; -0.0768167 0.0276985 … -…\n",
       "  \"7\"       => [0.0 0.105847 … 0.240075 0.375942; 0.0 0.0276985 … 0.0 0.180072]\n",
       "  \"8\"       => [0.0 0.105847 … 0.240075 0.375942; 0.0 0.0276985 … 0.0 0.180072]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tensors\n",
    "\n",
    "# nice! they are calculated <3\n",
    "# but how did it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward gets a model and a ModelLayer\n",
    "# if all the inputs have calculated values in model.tensor, it calls the KnetLayer: model_layer1.layer\n",
    "# with those tensors, and saves the output to model.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 5 entries:\n",
       "  \"5\"       => Nothing\n",
       "  \"input.1\" => Nothing\n",
       "  \"6\"       => Nothing\n",
       "  \"7\"       => Nothing\n",
       "  \"8\"       => Nothing"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's clear the tensors for a demo\n",
    "model = KnetModel(graph1);\n",
    "model.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"oops!\""
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(model, model_layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oops?\n",
    "# guess why? \n",
    "# input.1 is still nothing!\n",
    "# but how can we begin the calculations then?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(x) is the function:\n",
    "# function (m::KnetModel)(x)\n",
    "# and once we call model(x1) with our input, it takes x1 and saves it to model.tensors\n",
    "# once \"input.1\" has a value, our forward will work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 5 entries:\n",
       "  \"5\"       => Nothing\n",
       "  \"input.1\" => [1.74343 0.333645 … 0.216088 -0.295716; 0.813876 -2.47528 … 1.80…\n",
       "  \"6\"       => Nothing\n",
       "  \"7\"       => Nothing\n",
       "  \"8\"       => Nothing"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets do it by hand.\n",
    "model.tensors[\"input.1\"] = randn(100,5);\n",
    "model.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now our forward should work!\n",
    "forward(model, model_layer1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{AbstractString,1}:\n",
       " \"5\""
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which tensor do we expect to have a value now, instead of nothing?\n",
    "# let's see:\n",
    "model_layer1.outputs\n",
    "# it should be 5! \n",
    "# but a layer could have had multiple outputs :)\n",
    "# let's see if it worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 5 entries:\n",
       "  \"5\"       => [-0.666781 0.221056 … 0.298786 1.08357; -0.325639 0.782298 … -0.…\n",
       "  \"input.1\" => [1.74343 0.333645 … 0.216088 -0.295716; 0.813876 -2.47528 … 1.80…\n",
       "  \"6\"       => Nothing\n",
       "  \"7\"       => Nothing\n",
       "  \"8\"       => Nothing"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tensors\n",
    "# yay!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward begins\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×5 Array{Float64,2}:\n",
       " 0.0  0.105847   0.0       0.240075  0.375942\n",
       " 0.0  0.0276985  0.651835  0.0       0.180072"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so if the inputs, outputs are correctly specified in our ModelLayers,\n",
    "# model(x1) should fill all the tensors\n",
    "model(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 5 entries:\n",
       "  \"5\"       => [0.480554 -0.0127278 … -0.677104 -0.0401961; 0.754838 -0.0363629…\n",
       "  \"input.1\" => [-0.100092 0.412201 … 0.685679 0.12627; -0.318662 1.15254 … 1.41…\n",
       "  \"6\"       => [-0.21248 0.105847 … 0.240075 0.375942; -0.0768167 0.0276985 … -…\n",
       "  \"7\"       => [0.0 0.105847 … 0.240075 0.375942; 0.0 0.0276985 … 0.0 0.180072]\n",
       "  \"8\"       => [0.0 0.105847 … 0.240075 0.375942; 0.0 0.0276985 … 0.0 0.180072]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but did you realize that model(x1) also returned a tensor of size 2x5?\n",
    "# how did it know which one to return?\n",
    "# why did it return the tensor with name \"8\"?\n",
    "# is it because?\n",
    "# a) it is the output of the last layer we used\n",
    "# b) it is the final output specified by our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{String,1}:\n",
       " \"8\""
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model_outputs\n",
    "# (b) is correct!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the user does not care how and in which order the tensors are filled!\n",
    "# he only cares about the final output(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Perform a forward pass on the model: branch1.onnx\n",
    "# it is at the same folder with mlp.onnx\n",
    "# Tips:\n",
    "\n",
    "# 1) file_path = SET THE FILE PATH\n",
    "# 2) Create the graph\n",
    "# 3) Print it to see what it looks like\n",
    "# 4) turn it into a KnetModel\n",
    "# 5) create a dummy input x1. you should first figure out what the size of x1 should be \n",
    "#    by looking at the ModelLayers and their KnetLayers\n",
    "# 6) model(x1) and you are done\n",
    "\n",
    "# bonus:\n",
    "# 7) Fill model.tensors just by using forward, and not using model(x1)\n",
    "\n",
    "# the solutions are at: Test_branch1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
