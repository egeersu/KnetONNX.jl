{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Knet & ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Knet;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Pkg.installed() is deprecated\n",
      "└ @ Pkg /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Pkg/src/Pkg.jl:531\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "expected package `CodecZlib [944b1d66]` to exist in the manifest (use `resolve` to populate the manifest)",
     "output_type": "error",
     "traceback": [
      "expected package `CodecZlib [944b1d66]` to exist in the manifest (use `resolve` to populate the manifest)",
      "",
      "Stacktrace:",
      " [1] pkgerror(::String, ::Vararg{String,N} where N) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Pkg/src/Types.jl:53",
      " [2] package_info at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Pkg/src/Operations.jl:1519 [inlined]",
      " [3] #9 at ./none:0 [inlined]",
      " [4] iterate at ./generator.jl:47 [inlined]",
      " [5] _all(::Base.var\"#239#241\", ::Base.Generator{Array{Pkg.Types.PackageSpec,1},Pkg.API.var\"#9#10\"{Pkg.Types.Context}}, ::Colon) at ./reduce.jl:819",
      " [6] all at ./reduce.jl:815 [inlined]",
      " [7] Dict(::Base.Generator{Array{Pkg.Types.PackageSpec,1},Pkg.API.var\"#9#10\"{Pkg.Types.Context}}) at ./dict.jl:130",
      " [8] dependencies(::Pkg.Types.Context) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Pkg/src/API.jl:23",
      " [9] dependencies at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Pkg/src/API.jl:20 [inlined]",
      " [10] installed() at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.4/Pkg/src/Pkg.jl:532",
      " [11] top-level scope at /Users/syny/.julia/packages/Knet/bTNMd/data/mnist.jl:1",
      " [12] include(::String) at ./client.jl:439",
      " [13] top-level scope at In[3]:1"
     ]
    }
   ],
   "source": [
    "include(Knet.dir(\"data\",\"mnist.jl\"))\n",
    "dtrn,dtst = mnistdata();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KnetOnnx_PATH = \"/Users/syny/kafamagore/KnetOnnx.jl/src\"\n",
    "push!(LOAD_PATH, KnetOnnx_PATH)\n",
    "using KnetOnnx;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read ONNX Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = \"cnn.onnx\"\n",
    "file_path = \"/Users/syny/Downloads/bvlcalexnet-9.onnx\"\n",
    "graph = ONNXtoGraph(file_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnetOnnx.Types.Graph(Any[KnetOnnx.Types.Node(AbstractString[\"input.1\", \"conv1.weight\", \"conv1.bias\"], AbstractString[\"9\"], \"Conv_0\", \"Conv\", \"\", Dict{Any,Any}(:dilations => [1, 1],:group => 1,:pads => [0, 0, 0, 0],:kernel_shape => [3, 3],:strides => [1, 1]), \"\"), KnetOnnx.Types.Node(AbstractString[\"9\"], AbstractString[\"10\"], \"Relu_1\", \"Relu\", \"\", Dict{Any,Any}(), \"\"), KnetOnnx.Types.Node(AbstractString[\"10\", \"conv2.weight\", \"conv2.bias\"], AbstractString[\"11\"], \"Conv_2\", \"Conv\", \"\", Dict{Any,Any}(:dilations => [1, 1],:group => 1,:pads => [0, 0, 0, 0],:kernel_shape => [3, 3],:strides => [1, 1]), \"\"), KnetOnnx.Types.Node(AbstractString[\"11\"], AbstractString[\"12\"], \"MaxPool_3\", \"MaxPool\", \"\", Dict{Any,Any}(:pads => [0, 0, 0, 0],:kernel_shape => [2, 2],:strides => [2, 2]), \"\"), KnetOnnx.Types.Node(AbstractString[\"12\"], AbstractString[\"13\"], \"Flatten_4\", \"Flatten\", \"\", Dict{Any,Any}(:axis => 1), \"\"), KnetOnnx.Types.Node(AbstractString[\"13\", \"fc1.weight\", \"fc1.bias\"], AbstractString[\"14\"], \"Gemm_5\", \"Gemm\", \"\", Dict{Any,Any}(:alpha => 1.0f0,:beta => 1.0f0,:transB => 1), \"\"), KnetOnnx.Types.Node(AbstractString[\"14\"], AbstractString[\"15\"], \"Relu_6\", \"Relu\", \"\", Dict{Any,Any}(), \"\"), KnetOnnx.Types.Node(AbstractString[\"15\", \"fc2.weight\", \"fc2.bias\"], AbstractString[\"16\"], \"Gemm_7\", \"Gemm\", \"\", Dict{Any,Any}(:alpha => 1.0f0,:beta => 1.0f0,:transB => 1), \"\"), KnetOnnx.Types.Node(AbstractString[\"16\"], AbstractString[\"17\"], \"Softmax_8\", \"Softmax\", \"\", Dict{Any,Any}(:axis => 1), \"\")], \"torch-jit-export\", Dict{Any,Any}(\"conv1.bias\" => Float32[0.06703222, -0.14665703, -0.16295874, 0.29382768, 0.3088762, -0.011298269, 0.0490959, 0.20680758, -0.1455935, -0.18745951  …  -0.09966068, -0.19786108, 0.2747337, 0.22688434, 0.29555735, -0.15265676, -0.24357359, -0.06433573, 0.15489224, -0.28007862],\"fc1.bias\" => Float32[0.010289977, -0.004561679, 0.00034898613, 0.0056346143, -0.00061567966, -0.005501683, 0.0041796006, -0.0037543788, 0.0070406096, 0.0019513378  …  -8.821767f-5, 0.0016614189, 0.008180081, -0.007234154, 0.0042603957, -0.0026200525, 0.0064495737, 0.0025721574, 0.010392155, 0.0033835107],\"conv2.weight\" => Float32[-0.004649557 0.002430208 -0.026536513; -0.028791854 0.053006496 0.050967943; 0.024415564 -0.031024337 -0.024018835]\n",
       "\n",
       "Float32[-0.03910473 0.0504994 0.022208925; 0.022168215 0.031971116 0.0385645; -0.033013754 0.03783348 -0.039063834]\n",
       "\n",
       "Float32[-0.028672572 -0.020436503 -0.043744024; 0.052742865 -0.043386374 0.056913752; -0.036565304 0.018672314 0.0071004294]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[-0.038429953 0.02037641 0.024457756; 0.009738412 0.018035483 -0.0040638633; -0.026962738 -0.008977488 -0.046966985]\n",
       "\n",
       "Float32[0.051423397 -0.04005692 -0.04385511; -0.014089346 0.042085063 -0.02367583; 0.0034923367 0.04682224 -0.043597437]\n",
       "\n",
       "Float32[-0.044415537 -0.04456241 0.005756084; 0.035096887 -0.020150669 0.028148655; -0.058313187 -0.04585943 0.033834163]\n",
       "\n",
       "Float32[0.013879564 -0.030618949 0.050419983; -0.018767495 -0.049605098 0.0057429187; 0.039718557 0.00376359 0.056621026]\n",
       "\n",
       "Float32[0.0534561 -0.019650988 0.04319526; 0.053173665 0.010540921 0.046205956; -0.054337524 0.017971527 -0.014111314]\n",
       "\n",
       "Float32[0.032243874 0.018281084 -0.01902607; 0.05862699 0.044713188 0.01341426; 0.01961397 -0.042344693 0.028836835]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[-0.013690893 -0.034959517 0.036856767; 0.05562989 0.024946656 0.014777016; 0.0008683428 -0.049297296 0.04789288]\n",
       "\n",
       "Float32[0.011594046 0.042549726 -0.02163586; -0.0462216 0.04645933 0.041370075; 0.010985639 -0.017058503 0.055832494]\n",
       "\n",
       "Float32[-0.026645351 -0.048968766 -0.03185366; -0.050280012 0.05368151 -0.030157601; -0.05011426 0.046163376 0.032035705]\n",
       "\n",
       "Float32[-0.042431515 0.057805587 -0.019107156; 0.011485878 -0.037946403 -0.04462289; 0.004190173 -0.049316134 -0.04910505]\n",
       "\n",
       "Float32[-0.036940075 -0.057630364 0.010660712; 0.032637943 -0.023889605 0.04750352; -0.022652563 0.027931672 0.009537552]\n",
       "\n",
       "Float32[-0.009563521 -0.0074036494 0.003214091; 0.00567301 -0.025542058 -0.017488841; 0.0231683 0.0568381 0.0305621]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.0085112415 -0.037329745 0.042507734; 0.0055605583 0.050807577 -0.03745873; 0.02333207 -0.025567733 -0.0042036623]\n",
       "\n",
       "Float32[0.027706455 0.0060353987 0.03729898; 0.03072517 -0.04353836 -0.0060398243; -0.047678813 -0.0065020584 0.018761586]\n",
       "\n",
       "Float32[-0.046803042 0.01821043 -0.04881552; 0.048440848 0.008210648 -0.058635574; -0.04855685 0.04421216 0.047592316]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.046439555 0.007992443 0.0034406148; -0.050911516 0.04965688 0.020284954; -0.038996533 -0.019479211 0.027910266]\n",
       "\n",
       "Float32[0.00458676 -0.026082613 0.03502929; 0.03205167 0.009544779 -0.030380733; -0.03553599 0.03878713 0.007757101]\n",
       "\n",
       "Float32[-0.015527882 0.027461786 0.013129715; -0.024461329 -0.055308748 -0.05127313; -0.047558617 -0.05875605 0.019799199]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[-0.0060856827 -0.056926407 -0.021617133; -0.011707164 -0.016263302 0.048234995; 0.031116579 0.043935273 0.01521479]\n",
       "\n",
       "Float32[-0.045766033 -0.04552084 0.049815748; 0.042564783 -0.057939533 -0.012335554; 0.04588652 0.04955698 -0.035435818]\n",
       "\n",
       "Float32[0.0031578392 -0.017981075 -0.01908812; -0.044959612 0.013738949 0.051003214; -0.049365208 0.038611207 0.0072866045]\n",
       "\n",
       "Float32[0.017770667 0.04151522 -0.03187628; 0.050918896 -0.05203532 0.032835413; -0.025332693 0.015341204 -0.03117613]\n",
       "\n",
       "Float32[0.046598498 -0.037776824 0.033017922; -0.03530491 -0.034379087 -0.016783059; -0.0400234 -0.058879904 0.02521113]\n",
       "\n",
       "Float32[-0.032890424 -0.00071422756 -0.011997886; 0.028541695 -0.038346164 -0.006520666; 0.039747763 0.055884805 -0.021392308]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.019463208 -0.017653488 0.053495463; 0.05880336 -0.043641735 0.0539069; -0.010467619 -0.039738648 0.00017981976]\n",
       "\n",
       "Float32[-0.03004306 0.05088594 -0.023221433; -0.04528644 -0.025626428 0.04681075; 0.016932521 0.019051362 -0.012166988]\n",
       "\n",
       "Float32[0.020058025 0.011355605 0.037293274; 0.05383339 -0.021148045 -0.054592997; 0.020303022 0.007668365 0.011563342]\n",
       "\n",
       "Float32[0.035858136 0.058145527 -0.0009068735; -0.03187429 0.0417321 0.013629157; -0.053950213 0.057831552 -0.013649974]\n",
       "\n",
       "Float32[-0.05530161 0.033386532 0.0077159815; 0.03317154 0.01580843 0.055498037; -0.052587915 -0.052688815 0.037846316]\n",
       "\n",
       "Float32[-0.0038921349 -0.015292514 -0.028116936; 0.028223258 0.012028273 -0.033944108; -0.035936892 -0.024267044 0.015400987]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.03309801 -0.023240104 -0.037963156; 0.008134175 -0.058079258 0.0028193705; -0.027249783 -0.05396505 -0.0031196326]\n",
       "\n",
       "Float32[-0.029997654 -0.0011728257 -0.03874392; -0.042283542 0.0056435056 -0.057927478; -0.043952517 -0.05429957 -0.016581267]\n",
       "\n",
       "Float32[0.036809895 -0.011561289 0.032110978; 0.034977544 -0.0289684 0.03637961; 0.039014224 -0.047808155 0.054955255],\"fc1.weight\" => Float32[-0.009363047 0.00021234807 … -0.0020884192 0.0035806922; 0.0010722317 0.0066143805 … -8.1983395f-5 0.008273725; … ; -0.0019824095 -0.0062116757 … 0.0038673664 -0.0010849452; -0.0064942925 0.0076177837 … -0.0029080575 -0.003438524],\"conv1.weight\" => Float32[0.21051893 0.23792323 0.056135416; -0.22394952 -0.2711439 -0.14675319; -0.03921485 -0.2988239 0.2951143]\n",
       "\n",
       "Float32[0.33162513 0.12926593 0.0707722; -0.032912225 0.2244598 -0.23644488; 0.23089007 0.11358073 -0.18317458]\n",
       "\n",
       "Float32[-0.195599 -0.20473532 -0.2586478; 0.14180577 -0.18926132 -0.12537853; -0.10414517 0.30570057 0.03758654]\n",
       "\n",
       "...\n",
       "\n",
       "Float32[0.18500838 0.31485358 0.1985639; -0.07449344 -0.04446295 -0.29444727; -0.25161058 0.16226551 -0.05640748]\n",
       "\n",
       "Float32[0.022156239 -0.21350007 0.23714682; -0.028734893 -0.24008243 -0.1934242; -0.25631282 0.32337853 -0.2695814]\n",
       "\n",
       "Float32[0.15066695 0.2630851 0.31587306; 0.16366339 0.2095423 0.08567858; 0.14853135 0.23503688 -0.15338597],\"fc2.bias\" => Float32[0.060040615, -0.08186895, -0.02928301, -0.03197439, -0.037612468, 0.05444204, 0.08355767, -0.03974217, 0.0576782, -0.08235857],\"fc2.weight\" => Float32[-0.088356756 0.027203389 … -0.05532589 0.016590357; -0.021111168 0.010173261 … 0.08726523 -0.052367028; … ; 0.06557406 0.071241476 … 0.025800496 0.06872433; 0.021638252 -0.041525982 … 0.03594496 0.0042567775],\"conv2.bias\" => Float32[-0.00422851, 0.019842867, 0.030388203, 0.036061343, 0.009154651, 0.0118087195, -0.012999218, -0.00043279305, 0.052266758, -0.039524984  …  0.020890292, 0.032365378, -0.023713145, 0.016060468, -0.013692915, -0.030877132, -0.020124748, 0.02437323, -0.014953259, 0.05516457]), \"\", KnetOnnx.Types.ValueInfo[KnetOnnx.Types.ValueInfo(\"input.1\", \"\")], KnetOnnx.Types.ValueInfo[KnetOnnx.Types.ValueInfo(\"17\", \"\")], KnetOnnx.Types.ValueInfo[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model inputs: [\"data_0\", \"conv1_w_0\", \"conv1_b_0\", \"conv2_w_0\", \"conv2_b_0\", \"conv3_w_0\", \"conv3_b_0\", \"conv4_w_0\", \"conv4_b_0\", \"conv5_w_0\", \"conv5_b_0\", \"fc6_w_0\", \"fc6_b_0\", \"fc7_w_0\", \"fc7_b_0\", \"fc8_w_0\", \"fc8_b_0\", \"OC2_DUMMY_1\"]\n",
      "model outputs: [\"prob_1\"]\n",
      "(op1) Conv\n",
      "\tinput1: data_0\n",
      "\tinput2: conv1_w_0\n",
      "\tinput3: conv1_b_0\n",
      "\toutput1: conv1_1\n",
      "(op2) Relu\n",
      "\tinput1: conv1_1\n",
      "\toutput1: conv1_2\n",
      "(op3) LRN\n",
      "\tinput1: conv1_2\n",
      "\toutput1: norm1_1\n",
      "(op4) MaxPool\n",
      "\tinput1: norm1_1\n",
      "\toutput1: pool1_1\n",
      "(op5) Conv\n",
      "\tinput1: pool1_1\n",
      "\tinput2: conv2_w_0\n",
      "\tinput3: conv2_b_0\n",
      "\toutput1: conv2_1\n",
      "(op6) Relu\n",
      "\tinput1: conv2_1\n",
      "\toutput1: conv2_2\n",
      "(op7) LRN\n",
      "\tinput1: conv2_2\n",
      "\toutput1: norm2_1\n",
      "(op8) MaxPool\n",
      "\tinput1: norm2_1\n",
      "\toutput1: pool2_1\n",
      "(op9) Conv\n",
      "\tinput1: pool2_1\n",
      "\tinput2: conv3_w_0\n",
      "\tinput3: conv3_b_0\n",
      "\toutput1: conv3_1\n",
      "(op10) Relu\n",
      "\tinput1: conv3_1\n",
      "\toutput1: conv3_2\n",
      "(op11) Conv\n",
      "\tinput1: conv3_2\n",
      "\tinput2: conv4_w_0\n",
      "\tinput3: conv4_b_0\n",
      "\toutput1: conv4_1\n",
      "(op12) Relu\n",
      "\tinput1: conv4_1\n",
      "\toutput1: conv4_2\n",
      "(op13) Conv\n",
      "\tinput1: conv4_2\n",
      "\tinput2: conv5_w_0\n",
      "\tinput3: conv5_b_0\n",
      "\toutput1: conv5_1\n",
      "(op14) Relu\n",
      "\tinput1: conv5_1\n",
      "\toutput1: conv5_2\n",
      "(op15) MaxPool\n",
      "\tinput1: conv5_2\n",
      "\toutput1: pool5_1\n",
      "(op16) Reshape\n",
      "\tinput1: pool5_1\n",
      "\tinput2: OC2_DUMMY_1\n",
      "\toutput1: OC2_DUMMY_0\n",
      "(op17) Gemm\n",
      "\tinput1: OC2_DUMMY_0\n",
      "\tinput2: fc6_w_0\n",
      "\tinput3: fc6_b_0\n",
      "\toutput1: fc6_1\n",
      "(op18) Relu\n",
      "\tinput1: fc6_1\n",
      "\toutput1: fc6_2\n",
      "(op19) Dropout\n",
      "\tinput1: fc6_2\n",
      "\toutput1: fc6_3\n",
      "\toutput2: _fc6_mask_1\n",
      "(op20) Gemm\n",
      "\tinput1: fc6_3\n",
      "\tinput2: fc7_w_0\n",
      "\tinput3: fc7_b_0\n",
      "\toutput1: fc7_1\n",
      "(op21) Relu\n",
      "\tinput1: fc7_1\n",
      "\toutput1: fc7_2\n",
      "(op22) Dropout\n",
      "\tinput1: fc7_2\n",
      "\toutput1: fc7_3\n",
      "\toutput2: _fc7_mask_1\n",
      "(op23) Gemm\n",
      "\tinput1: fc7_3\n",
      "\tinput2: fc8_w_0\n",
      "\tinput3: fc8_b_0\n",
      "\toutput1: fc8_1\n",
      "(op24) Softmax\n",
      "\tinput1: fc8_1\n",
      "\toutput1: prob_1\n"
     ]
    }
   ],
   "source": [
    "PrintGraph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX Operation not yet implemented: LRN\n"
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching iterate(::Nothing)\nClosest candidates are:\n  iterate(!Matched::Core.SimpleVector) at essentials.jl:603\n  iterate(!Matched::Core.SimpleVector, !Matched::Any) at essentials.jl:603\n  iterate(!Matched::ExponentialBackOff) at error.jl:253\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching iterate(::Nothing)\nClosest candidates are:\n  iterate(!Matched::Core.SimpleVector) at essentials.jl:603\n  iterate(!Matched::Core.SimpleVector, !Matched::Any) at essentials.jl:603\n  iterate(!Matched::ExponentialBackOff) at error.jl:253\n  ...",
      "",
      "Stacktrace:",
      " [1] indexed_iterate(::Nothing, ::Int64) at ./tuple.jl:84",
      " [2] KnetOnnx.ModelLayer(::KnetOnnx.Types.Node, ::KnetOnnx.Types.Graph) at /Users/syny/kafamagore/KnetOnnx.jl/src/KnetModel.jl:77",
      " [3] get_ModelLayers(::KnetOnnx.Types.Graph) at /Users/syny/kafamagore/KnetOnnx.jl/src/KnetModel.jl:83",
      " [4] KnetModel at /Users/syny/kafamagore/KnetOnnx.jl/src/KnetModel.jl:26 [inlined]",
      " [5] KnetModel(::String) at /Users/syny/kafamagore/KnetOnnx.jl/src/KnetModel.jl:39",
      " [6] top-level scope at In[4]:1"
     ]
    }
   ],
   "source": [
    "model = KnetModel(file_path);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: ModelLayer not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: ModelLayer not defined",
      "",
      "Stacktrace:",
      " [1] get_ModelLayers(::KnetOnnx.Types.Graph) at ./In[10]:3",
      " [2] top-level scope at In[10]:6"
     ]
    }
   ],
   "source": [
    "function get_ModelLayers(g)\n",
    "    ModelLayers = []\n",
    "    for node in g.node; push!(ModelLayers, ModelLayer(node, g)); end\n",
    "    return ModelLayers\n",
    "end\n",
    "\n",
    "get_ModelLayers(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "type DataType has no field TensorDict",
     "output_type": "error",
     "traceback": [
      "type DataType has no field TensorDict",
      "",
      "Stacktrace:",
      " [1] getproperty(::Type{T} where T, ::Symbol) at ./Base.jl:28",
      " [2] top-level scope at In[5]:1"
     ]
    }
   ],
   "source": [
    "KnetModel.TensorDict(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-construct model in Knet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 11 entries:\n",
       "  \"12\"      => Nothing\n",
       "  \"input.1\" => Nothing\n",
       "  \"11\"      => Nothing\n",
       "  \"13\"      => Nothing\n",
       "  \"15\"      => Nothing\n",
       "  \"16\"      => Nothing\n",
       "  \"14\"      => Nothing\n",
       "  \"17\"      => Nothing\n",
       "  \"10\"      => Nothing\n",
       "  \"18\"      => Nothing\n",
       "  \"9\"       => Nothing"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: dtrn not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: dtrn not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[7]:1"
     ]
    }
   ],
   "source": [
    "x,y = first(dtrn)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 9 entries:\n",
       "  \"16\"      => [0.122901 0.129133 … 0.129186 0.11251; 0.0393511 0.0247273 … 0.0…\n",
       "  \"12\"      => Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.116799; … ; 0.0 0.0 ……\n",
       "  \"10\"      => Float32[0.238287 0.238287 … 0.238287 0.238287; 0.238287 0.238287…\n",
       "  \"15\"      => [0.0822569 0.0 … 0.0906895 0.0999589; 0.0 0.0 … 0.0 0.0; … ; 0.0…\n",
       "  \"input.1\" => Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 …\n",
       "  \"9\"       => Float32[0.238287 0.238287 … 0.238287 0.238287; 0.238287 0.238287…\n",
       "  \"11\"      => Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 …\n",
       "  \"13\"      => Float32[0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 …\n",
       "  \"14\"      => [0.0822569 -0.00749586 … 0.0906895 0.0999589; -0.0728656 -0.0673…"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy(model, dtst) = 0.1136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1136"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show accuracy(model, dtst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-train the model in Knet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: repeat(d::Data,n) is deprecated, use IterTools.ncycle instead.\n",
      "└ @ Knet /Users/syny/.julia/packages/Knet/bTNMd/src/data.jl:92\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stacktrace:\n",
      " [1] \u001b[1mgetindex\u001b[22m\u001b[1m(\u001b[22m::Array{String,1}, ::Int64\u001b[1m)\u001b[22m at \u001b[1m./array.jl:788\u001b[22m\n",
      " [2] \u001b[1m(::KnetModel)\u001b[22m\u001b[1m(\u001b[22m::Array{Float32,4}, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m at \u001b[1m/Users/syny/kafamagore/KnetOnnx.jl/src/KnetModel.jl:121\u001b[22m\n",
      " [3] \u001b[1m(::Knet.var\"#693#694\"{Knet.Minimize{Knet.Repeat},Tuple{Array{Float32,4},Array{UInt8,1}}})\u001b[22m\u001b[1m(\u001b[22m\u001b[1m)\u001b[22m at \u001b[1m/Users/syny/.julia/packages/AutoGrad/6QsMu/src/core.jl:205\u001b[22m\n",
      " [4] \u001b[1mdifferentiate\u001b[22m\u001b[1m(\u001b[22m::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}\u001b[1m)\u001b[22m at \u001b[1m/Users/syny/.julia/packages/AutoGrad/6QsMu/src/core.jl:144\u001b[22m\n",
      " [5] \u001b[1mdifferentiate\u001b[22m at \u001b[1m/Users/syny/.julia/packages/AutoGrad/6QsMu/src/core.jl:135\u001b[22m [inlined]\n",
      " [6] \u001b[1miterate\u001b[22m at \u001b[1m/Users/syny/.julia/packages/Knet/bTNMd/src/train.jl:23\u001b[22m [inlined]\n",
      " [7] \u001b[1miterate\u001b[22m at \u001b[1m/Users/syny/.julia/packages/Knet/bTNMd/src/progress.jl:69\u001b[22m [inlined]\n",
      " [8] \u001b[1mprogress!\u001b[22m\u001b[1m(\u001b[22m::Knet.Minimize{Knet.Repeat}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}\u001b[1m)\u001b[22m at \u001b[1m/Users/syny/.julia/packages/Knet/bTNMd/src/progress.jl:58\u001b[22m\n",
      " [9] \u001b[1mprogress!\u001b[22m\u001b[1m(\u001b[22m::Knet.Minimize{Knet.Repeat}\u001b[1m)\u001b[22m at \u001b[1m/Users/syny/.julia/packages/Knet/bTNMd/src/progress.jl:58\u001b[22m\n",
      " [10] top-level scope at \u001b[1mIn[11]:2\u001b[22m\n",
      " [11] \u001b[1meval\u001b[22m at \u001b[1m./boot.jl:331\u001b[22m [inlined]\n",
      " [12] \u001b[1msoftscope_include_string\u001b[22m\u001b[1m(\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m at \u001b[1m/Users/syny/.julia/packages/SoftGlobalScope/cSbw5/src/SoftGlobalScope.jl:218\u001b[22m\n",
      " [13] \u001b[1mexecute_request\u001b[22m\u001b[1m(\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m at \u001b[1m/Users/syny/.julia/packages/IJulia/DrVMH/src/execute_request.jl:67\u001b[22m\n",
      " [14] \u001b[1m#invokelatest#1\u001b[22m at \u001b[1m./essentials.jl:712\u001b[22m [inlined]\n",
      " [15] \u001b[1minvokelatest\u001b[22m at \u001b[1m./essentials.jl:711\u001b[22m [inlined]\n",
      " [16] \u001b[1meventloop\u001b[22m\u001b[1m(\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m at \u001b[1m/Users/syny/.julia/packages/IJulia/DrVMH/src/eventloop.jl:8\u001b[22m\n",
      " [17] \u001b[1m(::IJulia.var\"#15#18\")\u001b[22m\u001b[1m(\u001b[22m\u001b[1m)\u001b[22m at \u001b[1m./task.jl:358\u001b[22m\n"
     ]
    },
    {
     "ename": "BoundsError",
     "evalue": "BoundsError: attempt to access 1-element Array{String,1} at index [2]",
     "output_type": "error",
     "traceback": [
      "BoundsError: attempt to access 1-element Array{String,1} at index [2]",
      "",
      "Stacktrace:",
      " [1] differentiate(::Function; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /Users/syny/.julia/packages/AutoGrad/6QsMu/src/core.jl:148",
      " [2] differentiate at /Users/syny/.julia/packages/AutoGrad/6QsMu/src/core.jl:135 [inlined]",
      " [3] iterate at /Users/syny/.julia/packages/Knet/bTNMd/src/train.jl:23 [inlined]",
      " [4] iterate at /Users/syny/.julia/packages/Knet/bTNMd/src/progress.jl:69 [inlined]",
      " [5] progress!(::Knet.Minimize{Knet.Repeat}; o::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /Users/syny/.julia/packages/Knet/bTNMd/src/progress.jl:58",
      " [6] progress!(::Knet.Minimize{Knet.Repeat}) at /Users/syny/.julia/packages/Knet/bTNMd/src/progress.jl:58",
      " [7] top-level scope at In[11]:2"
     ]
    }
   ],
   "source": [
    "EPOCH = 2\n",
    "progress!(sgd(model, repeat(dtrn,EPOCH)))\n",
    "@show accuracy(model, dtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Images, Plots\n",
    "function predictMNIST(model, data)\n",
    "    i = rand(1:100)\n",
    "    x = reshape(rand(dtrn)[1][:,:,:,i], 28, 28, 1, 1)\n",
    "    pred = argmax(model(x), dims=1)[1][1]; if pred==10; pred=0; end\n",
    "    image = x[:,:,1,1]    \n",
    "    plot(heatmap(permutedims(image), yflip = true, title = (\"Model Output: \" * string(pred))))\n",
    "end\n",
    "predictMNIST(model, dtst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
